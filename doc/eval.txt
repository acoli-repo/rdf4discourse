evaluate against English

depth 0 (dm) vs. depth 3 (full PDTB depth)
predict en (col 19, zero counting)
average f1 score increases
the increase in recall is indeed due to an increase in true positives (and predicted discourse markers)
where does that come from ???
exceeding some thresholds?

ich habe *irgendwo* tp und fn verwechselt!
die zahlen für r sind p, die für p sind r!

avg		acc_dm	p_dm	r_dm	f_dm		acc_r	p_r	r_r	f_r
1		98.40%	28.92%	29.95%	28.86%		98.30%	20.35%	22.86%	21.23%
2		97.99%	29.07%	47.73%	35.82%		97.83%	21.00%	39.24%	27.08%
3		98.24%	33.47%	47.10%	38.98%		98.09%	24.89%	39.54%	30.44%
4		98.43%	37.37%	47.26%	41.66%		98.30%	28.84%	40.81%	33.76%
5		98.53%	40.11%	47.01%	43.26%		98.43%	32.86%	42.01%	36.86%
6		98.64%	43.37%	46.06%	44.67%		98.58%	38.19%	42.92%	40.42%

stddev
1		0.20%	13.40%	15.73%	14.04%		0.28%	14.05%	17.70%	15.55%
2		0.20%	3.48%	10.03%	4.83%		0.25%	7.07%	14.08%	9.11%
3		0.20%	4.17%	4.16%	3.58%		0.22%	5.97%	7.77%	6.61%
4		0.10%	2.72%	4.22%	2.85%		0.11%	4.73%	6.93%	5.50%
5		0.07%	2.11%	2.15%	1.79%		0.08%	4.23%	4.70%	4.38%

ursprüngliche experimente hatten nur das erste wort evaluiert, scores waren deutlich besser
der niedrige recall muss kein schlechtes zeichen sein
kann auch bedeuten, dass alignment-artefakte beseitigt wurden

ich kann das jetzt nicht lösen
- möglicherweise ist doch nicts verwechselt, denn mit steigendem threshold (-c)
sinkt mein (originaler) recall und steigt die (originale) precision
- dafür spriht auch, dass -th denselben effekt hat

two thresholds to optimize further
- --pred_threshold (-th): percentage of predictors for a given feature
- --min_confidence (-c): overall corpus: probability of a cue annotated as discourse marker, requires iteration

## -th

discourse 3

-th  | predicted dm					gold dm	tp	|	acc_dm	p_dm	r_dm	f_dm	|	acc_r	p_r	r_r	f_r
-1	[19]	<=	[7, 13, 25, 31, 37, 43]	24525	7332	5365	|	96.57%	21.88%	73.17%	33.68%	|	96.41%	17.83%	68.97%	28.34%
0	[19]	<=	[7, 13, 25, 31, 37, 43]	24525	7332	5365	|	96.57%	21.88%	73.17%	33.68%	|	96.41%	17.83%	68.97%	28.34%
0.01	[19]	<=	[7, 13, 25, 31, 37, 43]	24525	7332	5365	|	96.57%	21.88%	73.17%	33.68%	|	96.41%	17.83%	68.97%	28.34%
0.05	[19]	<=	[7, 13, 25, 31, 37, 43]	24525	7332	5365	|	96.57%	21.88%	73.17%	33.68%	|	96.41%	17.83%	68.97%	28.34%
0.1	[19]	<=	[7, 13, 25, 31, 37, 43]	24525	7332	5365	|	96.57%	21.88%	73.17%	33.68%	|	96.41%	17.83%	68.97%	28.34%
0.2	[19]	<=	[7, 13, 25, 31, 37, 43]	15895	7332	4737	|	97.77%	29.80%	64.61%	40.79%	|	97.64%	24.88%	60.38%	35.23%
0.3	[19]	<=	[7, 13, 25, 31, 37, 43]	12597	7332	4327	|	98.17%	34.35%	59.02%	43.42%	|	98.06%	29.02%	54.89%	37.97%

0.4	[19]	<=	[7, 13, 25, 31, 37, 43]	7787	7332	3377	|	98.64%	43.37%	46.06%	44.67%	|	98.58%	38.19%	42.92%	40.42%

0.5	[19]	<=	[7, 13, 25, 31, 37, 43]	5187	7332	2590	|	98.81%	49.93%	35.32%	41.38%	|	98.77%	45.25%	33.11%	38.24%
0.6	[19]	<=	[7, 13, 25, 31, 37, 43]	3733	7332	1933	|	98.83%	51.78%	26.36%	34.94%	|	98.80%	47.07%	24.55%	32.27%
0.7	[19]	<=	[7, 13, 25, 31, 37, 43]	2825	7332	1515	|	98.84%	53.63%	20.66%	29.83%	|	98.82%	49.13%	19.26%	27.68%
0.8	[19]	<=	[7, 13, 25, 31, 37, 43]	1299	7332	665	|	98.81%	51.19%	9.07%	15.41%	|	98.81%	47.50%	8.47%	14.38%
0.9	[19]	<=	[7, 13, 25, 31, 37, 43]	1152	7332	568	|	98.81%	49.31%	7.75%	13.39%	|	98.80%	45.66%	7.22%	12.46%
1	[19]	<=	[7, 13, 25, 31, 37, 43]	0	0	0	|	100.00%	0.00%	0.00%	0.00%	|	100.00%	0.00%	0.00%	0.00%

-th 0.4 (this is also default)

## -c

iterate: bootstrap discourse marker inventory, use it to disambiguate (if equal
predictor score, use P(sense|marker) over the corpus to predict the most likely
sense)

iteration:
- beinhaltet zusätzliches pruning: min. confidence score 0.25, min freq 10

best-performing configuration: (tested in steps of 0.1)

-th -c | predicted dm			gold dm	tp	|	acc_dm	p_dm	r_dm	f_dm	|	acc_r	p_r	r_r	f_r
0.4	0	7787	7332	3377	|	98.64%	43.37%	46.06%	44.67%	|	98.58%	38.76%	43.28%	40.89%

iteration (ohne threshold) verbessert die predictions marginal (hat keinen effekt auf diskursmarker)
wichtig ist aber, dass iteration eine (heuristische) disambiguierung gestattet, d.h. wir sagen tatsächlich nur einen sense voraus

Recall: der tatsächliche Recall liegt wohl etwas höher, da im alignment fehlvorhersagen gemacht werden, die hier als gold gelten
Precision: die tatsächliche precision liegt möglicherweise höher, da die annotation aus dem englischen heraus inhärent noisy ist

Diese Induktion liefert sowohl annotierte Daten als auch ein Diskursmarkerlexikon, sogar mit Frequenzinformation und Information über mögliche Ambiguitäten.
Die Evaluationsmetriken sind aber auch als Warnung zu verstehen, denn das Ergebnis erfordert manuelle Nacharbeit.
Im Minimalfall wird durch diese Methoden die lexikographische Arbeit an Diskursmarkern erleichtert, da es jetzt nur noch darum geht, Kandidaten zu selektieren und deren lesung zu bestätigen.
